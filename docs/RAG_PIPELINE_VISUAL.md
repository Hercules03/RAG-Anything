# RAG-Anything Visual Pipeline

A visual representation of how documents flow through RAG-Anything.

## ğŸ“Š Complete Pipeline Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         STREAMLIT WEB INTERFACE                          â”‚
â”‚  User uploads PDF â†’ Temporary storage â†’ Process button clicked          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1: DOCUMENT PARSING (MinerU)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: research_paper.pdf                                               â”‚
â”‚                                                                          â”‚
â”‚  MinerU analyzes:                                                        â”‚
â”‚  â”œâ”€ Layout detection (headers, paragraphs, columns)                     â”‚
â”‚  â”œâ”€ Image extraction (figures, diagrams, charts)                        â”‚
â”‚  â”œâ”€ Table recognition (converts to markdown)                            â”‚
â”‚  â”œâ”€ Equation detection (extracts LaTeX)                                 â”‚
â”‚  â””â”€ Text extraction (with OCR fallback)                                 â”‚
â”‚                                                                          â”‚
â”‚  Output: content_list = [                                               â”‚
â”‚    {type: "text", text: "Introduction...", page_idx: 0},               â”‚
â”‚    {type: "image", img_path: "/path/fig1.jpg", page_idx: 1},           â”‚
â”‚    {type: "table", table_body: "| A | B |...", page_idx: 2},           â”‚
â”‚    {type: "equation", latex: "E=mc^2", page_idx: 3}                    â”‚
â”‚  ]                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 2: CONTENT SEPARATION                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  separate_content(content_list)                                          â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   TEXT CONTENT     â”‚              â”‚  MULTIMODAL CONTENT   â”‚           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚  â”‚ "Introduction...   â”‚              â”‚ â€¢ 5 images            â”‚           â”‚
â”‚  â”‚  Methodology...    â”‚              â”‚ â€¢ 3 tables            â”‚           â”‚
â”‚  â”‚  Results...        â”‚              â”‚ â€¢ 2 equations         â”‚           â”‚
â”‚  â”‚  Conclusion..."    â”‚              â”‚                       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚           â”‚                                    â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                    â”‚
            â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: TEXT PATH       â”‚      â”‚  PHASE 4: MULTIMODAL PATH          â”‚
â”‚  (LightRAG Processing)    â”‚      â”‚  (Modal Processors)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                           â”‚      â”‚                                    â”‚
â”‚ Step 1: Chunking          â”‚      â”‚ FOR EACH MULTIMODAL ITEM:          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      â”‚                                    â”‚
â”‚ â”‚ Chunk 1: Intro... â”‚     â”‚      â”‚ Step 1: Extract Context            â”‚
â”‚ â”‚ Chunk 2: Method...â”‚     â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ â”‚ Chunk 3: Results..â”‚     â”‚      â”‚ â”‚ Text before: "Figure 1..." â”‚     â”‚
â”‚ â”‚ Chunk 4: Concl... â”‚     â”‚      â”‚ â”‚ Caption: "Architecture"    â”‚     â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      â”‚ â”‚ Text after: "The system..."â”‚     â”‚
â”‚         â”‚                 â”‚      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â–¼                 â”‚      â”‚         â”‚                          â”‚
â”‚ Step 2: Entity Extract    â”‚      â”‚         â–¼                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      â”‚ Step 2: Process by Type            â”‚
â”‚ â”‚ LLM analyzes:     â”‚     â”‚      â”‚                                    â”‚
â”‚ â”‚ â€¢ RAG-Anything    â”‚     â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ â€¢ LightRAG        â”‚     â”‚      â”‚ â”‚ IMAGE â†’ VLM Caption         â”‚    â”‚
â”‚ â”‚ â€¢ Knowledge Graph â”‚     â”‚      â”‚ â”‚ TABLE â†’ LLM Analysis        â”‚    â”‚
â”‚ â”‚ â€¢ MinerU          â”‚     â”‚      â”‚ â”‚ EQUATION â†’ LLM Explanation  â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                 â”‚      â”‚         â”‚                          â”‚
â”‚         â–¼                 â”‚      â”‚         â–¼                          â”‚
â”‚ Step 3: Relation Extract  â”‚      â”‚ Step 3: Create Multimodal Doc      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ â”‚ LLM identifies:   â”‚     â”‚      â”‚ â”‚ [IMAGE: fig1.jpg]          â”‚     â”‚
â”‚ â”‚ RAG-Anything      â”‚     â”‚      â”‚ â”‚ Context: "Section 3..."    â”‚     â”‚
â”‚ â”‚   â†“ BASED_ON      â”‚     â”‚      â”‚ â”‚ Caption: "Shows the..."    â”‚     â”‚
â”‚ â”‚ LightRAG          â”‚     â”‚      â”‚ â”‚ Page: 1                    â”‚     â”‚
â”‚ â”‚   â†“ USES          â”‚     â”‚      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚ â”‚ Knowledge Graph   â”‚     â”‚      â”‚         â”‚                          â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      â”‚         â–¼                          â”‚
â”‚         â”‚                 â”‚      â”‚ Step 4: Insert into LightRAG       â”‚
â”‚         â–¼                 â”‚      â”‚ (Same as text path â†’)              â”‚
â”‚ Step 4: Vector Embeddings â”‚      â”‚                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ Embed each chunk: â”‚     â”‚                       â”‚
â”‚ â”‚ [0.12, 0.45, ...] â”‚     â”‚                       â”‚
â”‚ â”‚ 768 dimensions    â”‚     â”‚                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                       â”‚
â”‚         â”‚                 â”‚                       â”‚
â”‚         â–¼                 â”‚                       â”‚
â”‚ Step 5: Build Graph       â”‚                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚                       â”‚
â”‚ â”‚  [Entity Nodes]   â”‚     â”‚                       â”‚
â”‚ â”‚       +           â”‚     â”‚                       â”‚
â”‚ â”‚  [Relations]      â”‚     â”‚                       â”‚
â”‚ â”‚       +           â”‚     â”‚                       â”‚
â”‚ â”‚  [Chunk Nodes]    â”‚     â”‚                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
            â”‚                                       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 5: STORAGE LAYER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ./rag_storage/                                                          â”‚
â”‚  â”œâ”€ graph_chunk_entity_relation.graphml  â† Knowledge Graph              â”‚
â”‚  â”‚    Nodes: [RAG-Anything] [LightRAG] [Chunk1] [Chunk2] ...           â”‚
â”‚  â”‚    Edges: BASED_ON, USES, INCLUDES, RELATES_TO ...                   â”‚
â”‚  â”‚                                                                       â”‚
â”‚  â”œâ”€ vdb_chunks.json  â† Vector Database                                  â”‚
â”‚  â”‚    {                                                                  â”‚
â”‚  â”‚      "chunk_1": {"embedding": [0.12, ...], "text": "..."},          â”‚
â”‚  â”‚      "chunk_2": {"embedding": [0.45, ...], "text": "..."}           â”‚
â”‚  â”‚    }                                                                  â”‚
â”‚  â”‚                                                                       â”‚
â”‚  â”œâ”€ kv_store_full_entities.json  â† Entity Store                         â”‚
â”‚  â”‚    {                                                                  â”‚
â”‚  â”‚      "RAG-Anything": {"type": "SYSTEM", "desc": "..."},             â”‚
â”‚  â”‚      "LightRAG": {"type": "FRAMEWORK", "desc": "..."}               â”‚
â”‚  â”‚    }                                                                  â”‚
â”‚  â”‚                                                                       â”‚
â”‚  â”œâ”€ kv_store_full_relations.json  â† Relation Store                      â”‚
â”‚  â”‚    [                                                                  â”‚
â”‚  â”‚      {"src": "RAG-Anything", "tgt": "LightRAG", "rel": "BASED_ON"}, â”‚
â”‚  â”‚      {"src": "LightRAG", "tgt": "Knowledge Graph", "rel": "USES"}   â”‚
â”‚  â”‚    ]                                                                  â”‚
â”‚  â”‚                                                                       â”‚
â”‚  â””â”€ parse_cache.json  â† Parsing Cache (for reuse)                       â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
                    DOCUMENT PROCESSING COMPLETE!
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER ASKS QUESTION IN CHAT                            â”‚
â”‚  "What is RAG-Anything and how does it work?"                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 6: HYBRID QUERY PROCESSING                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Step 1: Vector Search (Similarity)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚ 1. Embed query: "What is RAG-Anything" â”‚                             â”‚
â”‚  â”‚    â†’ [0.23, 0.56, ..., 0.89]           â”‚                             â”‚
â”‚  â”‚                                         â”‚                             â”‚
â”‚  â”‚ 2. Find similar chunks (cosine sim):   â”‚                             â”‚
â”‚  â”‚    â€¢ Chunk 1: "RAG-Anything is..." 0.95â”‚                             â”‚
â”‚  â”‚    â€¢ Chunk 3: "The system uses..." 0.87â”‚                             â”‚
â”‚  â”‚    â€¢ Chunk 7: "Features include..." 0.82                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                          â”‚
â”‚  Step 2: Graph Traversal (Relationships)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚ 1. Extract entities from query:        â”‚                             â”‚
â”‚  â”‚    â†’ ["RAG-Anything"]                  â”‚                             â”‚
â”‚  â”‚                                         â”‚                             â”‚
â”‚  â”‚ 2. Find in knowledge graph:            â”‚                             â”‚
â”‚  â”‚    [RAG-Anything] found!               â”‚                             â”‚
â”‚  â”‚                                         â”‚                             â”‚
â”‚  â”‚ 3. Get related entities (depth=2):     â”‚                             â”‚
â”‚  â”‚    [RAG-Anything]                      â”‚                             â”‚
â”‚  â”‚       â”œâ”€BASED_ONâ†’ [LightRAG]           â”‚                             â”‚
â”‚  â”‚       â”œâ”€INCLUDESâ†’ [MinerU]             â”‚                             â”‚
â”‚  â”‚       â””â”€SUPPORTSâ†’ [Multimodal]         â”‚                             â”‚
â”‚  â”‚                                         â”‚                             â”‚
â”‚  â”‚ 4. Get chunks for these entities       â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                          â”‚
â”‚  Step 3: Multimodal Retrieval                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚ Search captions/analyses for keywords: â”‚                             â”‚
â”‚  â”‚ â€¢ Figure 1: "RAG-Anything architecture"â”‚                             â”‚
â”‚  â”‚ â€¢ Table 2: "RAG-Anything performance"  â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                          â”‚
â”‚  Step 4: Combine All Context                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚ Context = {                            â”‚                             â”‚
â”‚  â”‚   vector_chunks: [Chunk1, Chunk3, ...],â”‚                             â”‚
â”‚  â”‚   graph_entities: [RAG, LightRAG, ...],â”‚                             â”‚
â”‚  â”‚   multimodal: [Fig1, Table2, ...]      â”‚                             â”‚
â”‚  â”‚ }                                      â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 7: ANSWER GENERATION                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  LLM Prompt:                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ You are a helpful assistant. Use the following context to      â”‚     â”‚
â”‚  â”‚ answer the question comprehensively.                           â”‚     â”‚
â”‚  â”‚                                                                 â”‚     â”‚
â”‚  â”‚ CONTEXT FROM DOCUMENT:                                         â”‚     â”‚
â”‚  â”‚                                                                 â”‚     â”‚
â”‚  â”‚ Text chunks:                                                   â”‚     â”‚
â”‚  â”‚ - RAG-Anything is a multimodal RAG system built on LightRAG... â”‚     â”‚
â”‚  â”‚ - The system uses knowledge graphs for entity relationships... â”‚     â”‚
â”‚  â”‚ - Features include document parsing, multimodal processing...  â”‚     â”‚
â”‚  â”‚                                                                 â”‚     â”‚
â”‚  â”‚ Related entities:                                              â”‚     â”‚
â”‚  â”‚ - RAG-Anything (SYSTEM): Multimodal RAG framework              â”‚     â”‚
â”‚  â”‚ - LightRAG (FRAMEWORK): Base framework for graph-based RAG     â”‚     â”‚
â”‚  â”‚ - MinerU (TOOL): Document parser for layout analysis           â”‚     â”‚
â”‚  â”‚                                                                 â”‚     â”‚
â”‚  â”‚ Multimodal content:                                            â”‚     â”‚
â”‚  â”‚ - Figure 1 (page 2): Shows RAG-Anything architecture with...  â”‚     â”‚
â”‚  â”‚ - Table 2 (page 5): Performance comparison showing 95.2%...    â”‚     â”‚
â”‚  â”‚                                                                 â”‚     â”‚
â”‚  â”‚ QUESTION: What is RAG-Anything and how does it work?          â”‚     â”‚
â”‚  â”‚                                                                 â”‚     â”‚
â”‚  â”‚ Please provide a comprehensive answer.                         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                â–¼                                         â”‚
â”‚  LLM (Ollama gpt-oss:20b) generates answer...                           â”‚
â”‚                                â–¼                                         â”‚
â”‚  Generated Answer:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ RAG-Anything is a comprehensive multimodal RAG system built on â”‚     â”‚
â”‚  â”‚ top of LightRAG framework. It processes documents containing   â”‚     â”‚
â”‚  â”‚ text, images, tables, and equations using MinerU parser for    â”‚     â”‚
â”‚  â”‚ high-fidelity extraction.                                      â”‚     â”‚
â”‚  â”‚                                                                 â”‚     â”‚
â”‚  â”‚ The system works by:                                           â”‚     â”‚
â”‚  â”‚ 1. Parsing documents to extract all content types              â”‚     â”‚
â”‚  â”‚ 2. Building knowledge graphs with entity relationships         â”‚     â”‚
â”‚  â”‚ 3. Processing multimodal content with specialized processors   â”‚     â”‚
â”‚  â”‚ 4. Using hybrid retrieval combining vector and graph search    â”‚     â”‚
â”‚  â”‚                                                                 â”‚     â”‚
â”‚  â”‚ As shown in Figure 1 on page 2, the architecture includes...   â”‚     â”‚
â”‚  â”‚ Performance results in Table 2 demonstrate 95.2% accuracy...   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ANSWER DISPLAYED IN STREAMLIT                         â”‚
â”‚  User sees comprehensive answer with context from all modalities!       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Comparison: Traditional vs RAG-Anything

```
TRADITIONAL RAG:
================
PDF â†’ Simple text extract â†’ Fixed chunks (512 tokens)
                                   â†“
                         Vector embeddings only
                                   â†“
                            Vector DB storage
                                   â†“
                Query â†’ Vector similarity search only
                                   â†“
              LLM with limited text-only context
                                   â†“
                     Basic text-based answer


RAG-ANYTHING:
=============
PDF â†’ MinerU (layout analysis)
         â†“
    [Text] + [Images] + [Tables] + [Equations]
         â†“                           â†“
    Intelligent         Modal Processors (VLM/LLM)
    Chunking                       â†“
         â†“                    Caption + Analysis
    Entity/Relation                â†“
    Extraction          Convert to text descriptions
         â†“                           â†“
    Knowledge Graph â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         +
    Vector DB
         +
    KV Stores
         â†“
Query â†’ Hybrid Search (Vector + Graph + Multimodal)
         â†“
    Rich context from all modalities
         â†“
    LLM with comprehensive context
         â†“
    Detailed answer with images/tables/equations referenced
```

## ğŸ“Š Data Flow Example

```
INPUT DOCUMENT (research_paper.pdf):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Page 1: Title & Abstract             â”‚
â”‚ Page 2: Introduction + Figure 1      â”‚
â”‚ Page 3: Methodology + Table 1        â”‚
â”‚ Page 4: Results + Equation 1         â”‚
â”‚ Page 5: Conclusion                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
        AFTER PARSING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ content_list = [                     â”‚
â”‚   {type: "text", text: "Abstract"}, â”‚
â”‚   {type: "text", text: "Intro"},    â”‚
â”‚   {type: "image", path: "fig1.jpg"}, â”‚
â”‚   {type: "text", text: "Method"},   â”‚
â”‚   {type: "table", body: "|A|B|"},   â”‚
â”‚   {type: "text", text: "Results"},  â”‚
â”‚   {type: "equation", latex: "..."},  â”‚
â”‚   {type: "text", text: "Concl"}     â”‚
â”‚ ]                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
      AFTER PROCESSING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ KNOWLEDGE GRAPH:                     â”‚
â”‚  [RAG-Anything] â”€BASED_ONâ†’ [LightRAG]â”‚
â”‚       â”‚                               â”‚
â”‚       â”œâ”€USESâ†’ [Knowledge Graph]       â”‚
â”‚       â”‚                               â”‚
â”‚       â””â”€INCLUDESâ†’ [Multimodal]        â”‚
â”‚                                       â”‚
â”‚ VECTOR DB:                            â”‚
â”‚  chunk_1: [0.12, ..., 0.67] (768-d)  â”‚
â”‚  chunk_2: [0.45, ..., 0.89] (768-d)  â”‚
â”‚  ...                                  â”‚
â”‚                                       â”‚
â”‚ MULTIMODAL:                           â”‚
â”‚  "Figure 1 shows RAG architecture..." â”‚
â”‚  "Table 1 displays performance..."    â”‚
â”‚  "Equation defines loss function..."  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
         READY FOR QUERIES!
```

## ğŸ¯ Query Example Flow

```
USER QUERY: "How does RAG-Anything handle images?"
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                     â–¼
    VECTOR SEARCH        GRAPH SEARCH
         â”‚                     â”‚
         â–¼                     â–¼
   Find similar chunks   Find "images" entity
   mentioning "images"   and related nodes
         â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           MULTIMODAL SEARCH
                    â”‚
                    â–¼
         Find image captions
         with relevant content
                    â”‚
                    â–¼
            COMBINE CONTEXT
                    â”‚
                    â–¼
               LLM PROMPT
                    â”‚
                    â–¼
    "RAG-Anything processes images using
     ImageModalProcessor which:
     1. Extracts images during parsing
     2. Uses VLM for caption generation
     3. Links to surrounding context
     4. Stores in knowledge graph

     As shown in Figure 1 (page 2)..."
```

---

**This visual guide shows how RAG-Anything transforms your documents into a rich, queryable knowledge base!** ğŸš€
